{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from docx import Document\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the text from the document and break down into individual sentences\n",
    "doc = Document(\"test.docx\")\n",
    "\n",
    "text_list = []\n",
    "for paragraph in doc.paragraphs:\n",
    "    text_list.append(sent_tokenize(paragraph.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the document to lower case and break the sentences into words\n",
    "word_list = []\n",
    "tokenizer = RegexpTokenizer(\"['/-/$Â£a-zA-Z0-9]+\", gaps=False)\n",
    "for i in range(len(text_list)):\n",
    "    for text in text_list[i]:\n",
    "        word_list.append(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to\n",
      "from\n",
      "in\n",
      "of\n",
      "to\n",
      "by\n",
      "and\n",
      "by\n",
      "up\n",
      "to\n",
      "of\n",
      "will\n",
      "and\n",
      "to\n",
      "from\n",
      "it\n",
      "to\n",
      "the\n",
      "in\n",
      "in\n",
      "the\n",
      "of\n",
      "the\n",
      "the\n",
      "out\n",
      "to\n",
      "it\n",
      "by\n",
      "between\n",
      "and\n",
      "while\n",
      "it\n",
      "by\n",
      "to\n",
      "for\n",
      "the\n",
      "the\n",
      "will\n",
      "to\n",
      "the\n",
      "the\n",
      "in\n",
      "that\n",
      "the\n",
      "to\n",
      "of\n",
      "the\n",
      "of\n",
      "it\n",
      "out\n",
      "in\n",
      "but\n",
      "the\n",
      "be\n",
      "under\n",
      "from\n",
      "the\n",
      "have\n",
      "at\n",
      "their\n",
      "in\n",
      "a\n",
      "a\n",
      "by\n",
      "the\n",
      "of\n",
      "the\n",
      "which\n",
      "for\n",
      "and\n",
      "which\n",
      "will\n",
      "the\n",
      "s\n",
      "the\n",
      "the\n",
      "and\n",
      "of\n",
      "our\n",
      "the\n",
      "the\n",
      "of\n",
      "and\n",
      "be\n",
      "but\n",
      "in\n",
      "the\n",
      "he\n",
      "to\n",
      "it\n",
      "of\n",
      "to\n",
      "it\n",
      "to\n",
      "a\n",
      "but\n",
      "in\n",
      "the\n",
      "and\n",
      "on\n",
      "it\n",
      "had\n",
      "to\n",
      "up\n",
      "it\n",
      "to\n",
      "a\n",
      "of\n",
      "a\n",
      "between\n",
      "and\n",
      "a\n",
      "of\n",
      "it\n",
      "as\n",
      "under\n",
      "up\n",
      "to\n",
      "the\n",
      "or\n",
      "on\n",
      "at\n",
      "the\n",
      "of\n",
      "by\n",
      "more\n",
      "than\n",
      "when\n",
      "the\n",
      "of\n",
      "the\n",
      "a\n",
      "in\n",
      "from\n",
      "the\n",
      "s\n",
      "in\n",
      "the\n",
      "at\n",
      "of\n",
      "on\n",
      "from\n",
      "a\n",
      "in\n",
      "the\n",
      "of\n",
      "the\n",
      "an\n",
      "at\n",
      "if\n",
      "below\n",
      "a\n",
      "s\n",
      "a\n",
      "that\n",
      "s\n",
      "too\n",
      "to\n",
      "that\n",
      "s\n",
      "the\n",
      "for\n",
      "he\n",
      "the\n",
      "s\n",
      "to\n",
      "in\n",
      "the\n",
      "but\n",
      "the\n",
      "of\n",
      "the\n",
      "it\n",
      "is\n",
      "out\n",
      "of\n",
      "it\n",
      "there\n",
      "s\n",
      "no\n",
      "how\n",
      "the\n",
      "of\n",
      "and\n",
      "will\n"
     ]
    }
   ],
   "source": [
    "#Remove all stopwords and calculate word frequency\n",
    "frequency_table = dict()\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "pstem = PorterStemmer()\n",
    "\n",
    "for words in word_list:\n",
    "    for word in words:\n",
    "        word = pstem.stem(word)\n",
    "        if word in stoplist:\n",
    "            print(word)\n",
    "        elif word in frequency_table:\n",
    "            frequency_table[word] += 1\n",
    "        else:\n",
    "            frequency_table[word] = 1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm for scoring a sentence by its words\n",
    "\n",
    "sentence_weight = pd.DataFrame(columns=['sentence','weight'])\n",
    "index = 0\n",
    "\n",
    "for sentence in word_list: \n",
    "    weight = 0\n",
    "    for word in frequency_table:\n",
    "        if word in sentence:\n",
    "            weight += frequency_table[word]\n",
    "            \n",
    "    av_weight = weight/len(sentence)       \n",
    "    sentence_weight.loc[index] = [sentence,av_weight]\n",
    "    index += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = sentence_weight['weight'].mean()\n",
    "final = []\n",
    "\n",
    "for weight in sentence_weight['weight']:\n",
    "    if weight >= threshold:\n",
    "        final.append(sentence_weight['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>[that, s, the, rub, for, shell, investors, he,...</td>\n",
       "      <td>1.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[anglo, dutch, oil, giant, to, cut, operating,...</td>\n",
       "      <td>1.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[royal, dutch, shell, plans, to, slash, $9bn, ...</td>\n",
       "      <td>1.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[shell, plans, to, slash, $9bn, from, spending...</td>\n",
       "      <td>1.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[ben, van, beurden, chief, executive, of, roya...</td>\n",
       "      <td>1.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[the, anglo, dutch, company, will, also, suspe...</td>\n",
       "      <td>1.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[shell, boss, ben, van, beurden, said, the, ne...</td>\n",
       "      <td>1.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[the, combination, of, steeply, falling, oil, ...</td>\n",
       "      <td>1.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[nicholas, hyett, an, equity, analyst, at, har...</td>\n",
       "      <td>1.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[shell, had, planned, to, spend, before, rampi...</td>\n",
       "      <td>1.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence    weight\n",
       "19  [that, s, the, rub, for, shell, investors, he,...  1.888889\n",
       "1   [anglo, dutch, oil, giant, to, cut, operating,...  1.823529\n",
       "4   [royal, dutch, shell, plans, to, slash, $9bn, ...  1.692308\n",
       "0   [shell, plans, to, slash, $9bn, from, spending...  1.545455\n",
       "2   [ben, van, beurden, chief, executive, of, roya...  1.529412\n",
       "6   [the, anglo, dutch, company, will, also, suspe...  1.523810\n",
       "10  [shell, boss, ben, van, beurden, said, the, ne...  1.518519\n",
       "11  [the, combination, of, steeply, falling, oil, ...  1.481481\n",
       "18  [nicholas, hyett, an, equity, analyst, at, har...  1.354839\n",
       "13  [shell, had, planned, to, spend, before, rampi...  1.272727"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_weight.sort_values(by=['weight'],ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlem = WordNetLemmatizer()\n",
    "\n",
    "for words in word_list:\n",
    "    for word in words:\n",
    "        word = wlem.lemmatize(word)\n",
    "\n",
    "#words = \" \".join(without_stopwords)\n",
    "\n",
    "#wordcloud = WordCloud(width = 1200, height = 1200, \n",
    "                #background_color ='white', \n",
    "              #stopwords = stopwords, \n",
    "               # min_font_size = 5).generate(words)\n",
    "  \n",
    "    # plot the WordCloud image                        \n",
    "#plt.figure(figsize = (20, 15), facecolor = None) \n",
    "#plt.imshow(wordcloud) \n",
    "#plt.axis(\"off\") \n",
    "#plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('there', 's', 'no', 'knowing', 'exactly', 'how', 'long')]\n"
     ]
    }
   ],
   "source": [
    "#first try\n",
    "article_summary = []\n",
    "\n",
    "for sentence in sentence_weight:\n",
    "    if sentence_weight[sentence] >= threshold:\n",
    "        article_summary.append(sentence)\n",
    "\n",
    "print(article_summary)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
