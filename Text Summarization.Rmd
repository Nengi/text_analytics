---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.4.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import nltk
from nltk import sent_tokenize, RegexpTokenizer
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from docx import Document
import pandas as pd
```

```{python}
#Get all the text from the document and break down into individual sentences
doc = Document("test.docx")

text_list = []
for paragraph in doc.paragraphs:
    text_list.append(sent_tokenize(paragraph.text))
```

```{python}
#Convert the document to lower case and break the sentences into words
word_list = []
tokenizer = RegexpTokenizer("['/-/$Â£a-zA-Z0-9]+", gaps=False)
for i in range(len(text_list)):
    for text in text_list[i]:
        word_list.append(tokenizer.tokenize(text.lower()))
```

```{python}
#Remove all stopwords and calculate word frequency
frequency_table = dict()

stoplist = stopwords.words('english')
pstem = PorterStemmer()

for words in word_list:
    for word in words:
        word = pstem.stem(word)
        if word in stoplist:
            print(word)
        elif word in frequency_table:
            frequency_table[word] += 1
        else:
            frequency_table[word] = 1          
```

```{python}
# Algorithm for scoring a sentence by its words

sentence_weight = pd.DataFrame(columns=['sentence','weight'])
index = 0

for sentence in word_list: 
    weight = 0
    for word in frequency_table:
        if word in sentence:
            weight += frequency_table[word]
            
    av_weight = weight/len(sentence)       
    sentence_weight.loc[index] = [sentence,av_weight]
    index += 1            
```

```{python}
threshold = sentence_weight['weight'].mean()
final = []

for weight in sentence_weight['weight']:
    if weight >= threshold:
        final.append(sentence_weight['sentence'])
```

```{python}
sentence_weight.sort_values(by=['weight'],ascending=False).head(n=10)
```

```{python}


```

```{python}

```

```{python}
wlem = WordNetLemmatizer()

for words in word_list:
    for word in words:
        word = wlem.lemmatize(word)

#words = " ".join(without_stopwords)

#wordcloud = WordCloud(width = 1200, height = 1200, 
                #background_color ='white', 
              #stopwords = stopwords, 
               # min_font_size = 5).generate(words)
  
    # plot the WordCloud image                        
#plt.figure(figsize = (20, 15), facecolor = None) 
#plt.imshow(wordcloud) 
#plt.axis("off") 
#plt.tight_layout(pad = 0) 
  
plt.show()
        
```

```{python}

```

```{python}

```

```{python}
#first try
article_summary = []

for sentence in sentence_weight:
    if sentence_weight[sentence] >= threshold:
        article_summary.append(sentence)

print(article_summary)        
```
